{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a08d1f",
   "metadata": {},
   "source": [
    "# Proyecto 4: Encoder-Decoder vs Decoder-Only en Seq2Seq\n",
    "\n",
    "**Curso:** CC0C2 - Ciencias de la Computación\n",
    "\n",
    "**Objetivo:** Implementar y comparar dos arquitecturas Transformer en una tarea de reversión de secuencias.\n",
    "\n",
    "---\n",
    "\n",
    "## Índice\n",
    "\n",
    "1. Configuración del Entorno\n",
    "2. Generación del Corpus Sintético\n",
    "3. Tokenización\n",
    "4. Implementación de Modelos\n",
    "5. Entrenamiento\n",
    "6. Evaluación y Métricas\n",
    "7. Benchmarking\n",
    "8. Visualización de Resultados\n",
    "9. Análisis Comparativo\n",
    "10. Verificación de Reproducibilidad\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed98e5b0",
   "metadata": {},
   "source": [
    "## 1. Configuración del Entorno\n",
    "\n",
    "Instalación de dependencias necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e81bed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando dependencias...\n",
      "\n",
      "Instalando paquetes faltantes...\n",
      "Faltantes: pandas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instalación completada\n",
      "\n",
      "Versiones:\n",
      "PyTorch: 2.9.0\n",
      "NumPy: 2.3.4\n",
      "Matplotlib: 3.10.7\n",
      "Pandas: 2.3.3\n",
      "PyTorch: 2.9.0\n",
      "NumPy: 2.3.4\n",
      "Matplotlib: 3.10.7\n",
      "Pandas: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# Verificar e instalar dependencias\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Verificando dependencias...\\n\")\n",
    "\n",
    "packages = ['torch', 'numpy', 'matplotlib', 'pandas', 'pytest', 'pytest-cov']\n",
    "\n",
    "installed = []\n",
    "try:\n",
    "    import torch\n",
    "    installed.append('torch')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import numpy\n",
    "    installed.append('numpy')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import matplotlib\n",
    "    installed.append('matplotlib')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import pandas\n",
    "    installed.append('pandas')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "if len(installed) == len(packages[:4]):\n",
    "    print(\"Dependencias principales instaladas\")\n",
    "    print(f\"Paquetes: {', '.join(installed)}\")\n",
    "else:\n",
    "    print(\"Instalando paquetes faltantes...\")\n",
    "    missing = [p for p in packages[:4] if p not in installed]\n",
    "    print(f\"Faltantes: {', '.join(missing)}\")\n",
    "    \n",
    "    for package in missing:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
    "    \n",
    "    print(\"Instalación completada\")\n",
    "\n",
    "print(\"\\nVersiones:\")\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Matplotlib: {matplotlib.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bab67a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno: Local\n",
      "Directorio: /Users/work_profile/GitHub/UNI/Parcial-Encoder-Decoder_vs_Decoder-Only-en-Seq2Seq\n",
      "Estructura completa: src, tools, tests, docs, out, dist\n",
      "\n",
      "Resumen:\n",
      "  [OK] src/ (8 archivos)\n",
      "  [OK] tools/ (1 archivos)\n",
      "  [OK] tests/ (3 archivos)\n",
      "  [OK] docs/ (5 archivos)\n",
      "  [OK] out/ (6 archivos)\n",
      "  [OK] dist/ (8 archivos)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Detectar entorno\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    PROJECT_ROOT = '/content'\n",
    "    print(\"Entorno: Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    PROJECT_ROOT = os.getcwd()\n",
    "    print(\"Entorno: Local\")\n",
    "\n",
    "print(f\"Directorio: {PROJECT_ROOT}\")\n",
    "\n",
    "# Verificar estructura\n",
    "required_dirs = ['src', 'tools', 'tests', 'docs', 'out', 'dist']\n",
    "existing_dirs = [d for d in required_dirs if os.path.exists(os.path.join(PROJECT_ROOT, d))]\n",
    "\n",
    "if len(existing_dirs) == len(required_dirs):\n",
    "    print(f\"Estructura completa: {', '.join(existing_dirs)}\")\n",
    "else:\n",
    "    missing_dirs = [d for d in required_dirs if d not in existing_dirs]\n",
    "    for d in missing_dirs:\n",
    "        os.makedirs(os.path.join(PROJECT_ROOT, d), exist_ok=True)\n",
    "    print(f\"Directorios creados: {', '.join(missing_dirs)}\")\n",
    "\n",
    "# Configurar Python path\n",
    "src_path = os.path.join(PROJECT_ROOT, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(\"\\nResumen:\")\n",
    "for d in required_dirs:\n",
    "    dir_path = os.path.join(PROJECT_ROOT, d)\n",
    "    exists = \"OK\" if os.path.exists(dir_path) else \"NO\"\n",
    "    file_count = len(os.listdir(dir_path)) if os.path.exists(dir_path) else 0\n",
    "    print(f\"  [{exists}] {d}/ ({file_count} archivos)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16749e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Usando CPU\n"
     ]
    }
   ],
   "source": [
    "# Verificar disponibilidad de GPU\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Usando CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b11410f",
   "metadata": {},
   "source": [
    "## 2. Generación del Corpus Sintético\n",
    "\n",
    "Generación de 5000 pares de secuencias deterministas usando SHA256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a97e8e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tools/gen_corpus.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile tools/gen_corpus.sh\n",
    "#!/usr/bin/env bash\n",
    "set -euo pipefail\n",
    "\n",
    "SEED=\"${1:-42}\"\n",
    "SALT=\"${2:-deadbeef}\"\n",
    "VOCAB_SIZE=100\n",
    "MIN_LEN=3\n",
    "MAX_LEN=10\n",
    "NUM_SAMPLES=5000\n",
    "\n",
    "for i in $(seq 1 $NUM_SAMPLES); do\n",
    "  hash=$(echo -n \"${SEED}-${SALT}-${i}\" | sha256sum | awk '{print $1}')\n",
    "  len=$(( (0x${hash:0:2} % (MAX_LEN - MIN_LEN + 1)) + MIN_LEN ))\n",
    "  \n",
    "  tokens=()\n",
    "  for j in $(seq 0 $((len - 1))); do\n",
    "    offset=$(( j * 2 + 2 ))\n",
    "    tok=$(( 0x${hash:$offset:2} % VOCAB_SIZE ))\n",
    "    tokens+=($tok)\n",
    "  done\n",
    "  \n",
    "  src=\"\"\n",
    "  for tok in \"${tokens[@]}\"; do\n",
    "    src=\"${src}w${tok} \"\n",
    "  done\n",
    "  src=\"${src% }\"\n",
    "  \n",
    "  tgt=\"\"\n",
    "  for ((k=${#tokens[@]}-1; k>=0; k--)); do\n",
    "    tgt=\"${tgt}w${tokens[k]} \"\n",
    "  done\n",
    "  tgt=\"${tgt% }\"\n",
    "  \n",
    "  echo \"${src} ||| ${tgt}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0c42d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus generado\n",
      "Primeras 10 líneas:\n",
      "Primeras 10 líneas:\n",
      "w94 w86 w77 w98 w30 w88 ||| w88 w30 w98 w77 w86 w94\n",
      "w24 w10 w59 w94 ||| w94 w59 w10 w24\n",
      "w87 w55 w85 w36 w45 w94 w7 ||| w7 w94 w45 w36 w85 w55 w87\n",
      "w43 w76 w58 w72 ||| w72 w58 w76 w43\n",
      "w91 w27 w52 w12 ||| w12 w52 w27 w91\n",
      "w24 w42 w76 w48 w7 w79 w88 w99 ||| w99 w88 w79 w7 w48 w76 w42 w24\n",
      "w96 w50 w39 w47 w46 w68 w76 w13 ||| w13 w76 w68 w46 w47 w39 w50 w96\n",
      "w68 w26 w63 w43 w93 w32 w46 w38 ||| w38 w46 w32 w93 w43 w63 w26 w68\n",
      "w19 w5 w7 w13 w12 w6 ||| w6 w12 w13 w7 w5 w19\n",
      "w21 w35 w3 w3 w30 w61 ||| w61 w30 w3 w3 w35 w21\n",
      "w94 w86 w77 w98 w30 w88 ||| w88 w30 w98 w77 w86 w94\n",
      "w24 w10 w59 w94 ||| w94 w59 w10 w24\n",
      "w87 w55 w85 w36 w45 w94 w7 ||| w7 w94 w45 w36 w85 w55 w87\n",
      "w43 w76 w58 w72 ||| w72 w58 w76 w43\n",
      "w91 w27 w52 w12 ||| w12 w52 w27 w91\n",
      "w24 w42 w76 w48 w7 w79 w88 w99 ||| w99 w88 w79 w7 w48 w76 w42 w24\n",
      "w96 w50 w39 w47 w46 w68 w76 w13 ||| w13 w76 w68 w46 w47 w39 w50 w96\n",
      "w68 w26 w63 w43 w93 w32 w46 w38 ||| w38 w46 w32 w93 w43 w63 w26 w68\n",
      "w19 w5 w7 w13 w12 w6 ||| w6 w12 w13 w7 w5 w19\n",
      "w21 w35 w3 w3 w30 w61 ||| w61 w30 w3 w3 w35 w21\n",
      "\n",
      "Últimas 5 líneas:\n",
      "\n",
      "Últimas 5 líneas:\n",
      "w90 w16 w14 w55 ||| w55 w14 w16 w90\n",
      "w54 w94 w40 w33 w73 w39 w53 ||| w53 w39 w73 w33 w40 w94 w54\n",
      "w8 w46 w82 w97 w21 w84 w25 w83 w37 ||| w37 w83 w25 w84 w21 w97 w82 w46 w8\n",
      "w69 w60 w35 w74 w52 w37 w26 w48 w47 ||| w47 w48 w26 w37 w52 w74 w35 w60 w69\n",
      "w32 w71 w94 w5 ||| w5 w94 w71 w32\n",
      "w90 w16 w14 w55 ||| w55 w14 w16 w90\n",
      "w54 w94 w40 w33 w73 w39 w53 ||| w53 w39 w73 w33 w40 w94 w54\n",
      "w8 w46 w82 w97 w21 w84 w25 w83 w37 ||| w37 w83 w25 w84 w21 w97 w82 w46 w8\n",
      "w69 w60 w35 w74 w52 w37 w26 w48 w47 ||| w47 w48 w26 w37 w52 w74 w35 w60 w69\n",
      "w32 w71 w94 w5 ||| w5 w94 w71 w32\n",
      "\n",
      "Total de líneas:\n",
      "\n",
      "Total de líneas:\n",
      "    5000 out/corpus.txt\n",
      "    5000 out/corpus.txt\n"
     ]
    }
   ],
   "source": [
    "# Hacer el script ejecutable y generar corpus\n",
    "!chmod +x tools/gen_corpus.sh\n",
    "!bash tools/gen_corpus.sh 42 1a2b3c4d5e6f7890abcdef1234567890 > out/corpus.txt\n",
    "\n",
    "# Guardar metadata\n",
    "!echo \"Comando: ./tools/gen_corpus.sh 42 1a2b3c4d5e6f7890abcdef1234567890\" > out/seed.txt\n",
    "!sha256sum out/corpus.txt | awk '{print $1}' > out/corpus_sha256.txt\n",
    "\n",
    "print(\"Corpus generado\")\n",
    "!echo \"Primeras 10 líneas:\"\n",
    "!head -10 out/corpus.txt\n",
    "!echo \"\\nÚltimas 5 líneas:\"\n",
    "!tail -5 out/corpus.txt\n",
    "!echo \"\\nTotal de líneas:\"\n",
    "!wc -l out/corpus.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261bfd19",
   "metadata": {},
   "source": [
    "## 3. Tokenización\n",
    "\n",
    "Construcción del vocabulario y tokenización del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0f94a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo corpus desde out/corpus.txt...\n",
      "Construyendo vocabulario (min_freq=1)...\n",
      "Vocabulario: 104 tokens\n",
      "Vocabulario guardado en out/vocab.txt\n",
      "Tokenizando y guardando en out/tokens.jsonl...\n",
      "✓ Tokenización completada: 5000 ejemplos\n",
      "✓ Vocabulario: 104 tokens\n",
      "✓ Tokenización completada: 5000 ejemplos\n",
      "✓ Vocabulario: 104 tokens\n",
      "\n",
      "Tokenización completada\n",
      "\n",
      "Tokenización completada\n",
      "Vocabulario (primeras 20 líneas):\n",
      "Vocabulario (primeras 20 líneas):\n",
      "<PAD>\t0\n",
      "<SOS>\t1\n",
      "<EOS>\t2\n",
      "<UNK>\t3\n",
      "w94\t4\n",
      "w86\t5\n",
      "w77\t6\n",
      "w98\t7\n",
      "w30\t8\n",
      "w88\t9\n",
      "w24\t10\n",
      "w10\t11\n",
      "w59\t12\n",
      "w87\t13\n",
      "w55\t14\n",
      "w85\t15\n",
      "w36\t16\n",
      "w45\t17\n",
      "w7\t18\n",
      "w43\t19\n",
      "<PAD>\t0\n",
      "<SOS>\t1\n",
      "<EOS>\t2\n",
      "<UNK>\t3\n",
      "w94\t4\n",
      "w86\t5\n",
      "w77\t6\n",
      "w98\t7\n",
      "w30\t8\n",
      "w88\t9\n",
      "w24\t10\n",
      "w10\t11\n",
      "w59\t12\n",
      "w87\t13\n",
      "w55\t14\n",
      "w85\t15\n",
      "w36\t16\n",
      "w45\t17\n",
      "w7\t18\n",
      "w43\t19\n",
      "\n",
      "Ejemplos tokenizados (primeros 3):\n",
      "\n",
      "Ejemplos tokenizados (primeros 3):\n",
      "{\"id\": 0, \"src_text\": \"w94 w86 w77 w98 w30 w88\", \"tgt_text\": \"w88 w30 w98 w77 w86 w94\", \"src_ids\": [4, 5, 6, 7, 8, 9], \"tgt_ids\": [9, 8, 7, 6, 5, 4]}\n",
      "{\"id\": 1, \"src_text\": \"w24 w10 w59 w94\", \"tgt_text\": \"w94 w59 w10 w24\", \"src_ids\": [10, 11, 12, 4], \"tgt_ids\": [4, 12, 11, 10]}\n",
      "{\"id\": 2, \"src_text\": \"w87 w55 w85 w36 w45 w94 w7\", \"tgt_text\": \"w7 w94 w45 w36 w85 w55 w87\", \"src_ids\": [13, 14, 15, 16, 17, 4, 18], \"tgt_ids\": [18, 4, 17, 16, 15, 14, 13]}\n",
      "{\"id\": 0, \"src_text\": \"w94 w86 w77 w98 w30 w88\", \"tgt_text\": \"w88 w30 w98 w77 w86 w94\", \"src_ids\": [4, 5, 6, 7, 8, 9], \"tgt_ids\": [9, 8, 7, 6, 5, 4]}\n",
      "{\"id\": 1, \"src_text\": \"w24 w10 w59 w94\", \"tgt_text\": \"w94 w59 w10 w24\", \"src_ids\": [10, 11, 12, 4], \"tgt_ids\": [4, 12, 11, 10]}\n",
      "{\"id\": 2, \"src_text\": \"w87 w55 w85 w36 w45 w94 w7\", \"tgt_text\": \"w7 w94 w45 w36 w85 w55 w87\", \"src_ids\": [13, 14, 15, 16, 17, 4, 18], \"tgt_ids\": [18, 4, 17, 16, 15, 14, 13]}\n"
     ]
    }
   ],
   "source": [
    "# Nota: Aquí deberías pegar el contenido de src/tokenizer.py\n",
    "# o cargarlo desde el archivo si ya está en el proyecto\n",
    "\n",
    "# Por brevedad, ejecutamos directamente el script\n",
    "!python src/tokenizer.py out/corpus.txt --output out/tokens.jsonl --vocab out/vocab.txt\n",
    "\n",
    "print(\"\\nTokenización completada\")\n",
    "!echo \"Vocabulario (primeras 20 líneas):\"\n",
    "!head -20 out/vocab.txt\n",
    "!echo \"\\nEjemplos tokenizados (primeros 3):\"\n",
    "!head -3 out/tokens.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ece819",
   "metadata": {},
   "source": [
    "## 4. Implementación de Modelos\n",
    "\n",
    "### 4.1 Módulo de Atención"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21ab7be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Módulo de atención cargado\n",
      "Input shape: torch.Size([2, 10, 128])\n",
      "Output shape: torch.Size([2, 10, 128])\n",
      "Attention weights shape: torch.Size([2, 4, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "# Cargar módulo de atención desde src/attention.py\n",
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "from attention import (\n",
    "    ScaledDotProductAttention,\n",
    "    MultiHeadAttention,\n",
    "    PositionalEncoding,\n",
    "    create_padding_mask,\n",
    "    create_causal_mask\n",
    ")\n",
    "\n",
    "print(\"Módulo de atención cargado\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "import torch\n",
    "\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "\n",
    "mha = MultiHeadAttention(d_model, num_heads)\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "output, attn_weights = mha(x, x, x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Attention weights shape: {attn_weights.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d751369",
   "metadata": {},
   "source": [
    "### 4.2 Arquitecturas Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2da2dc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos instanciados\n",
      "  Encoder-Decoder: 965,736 parámetros\n",
      "  Decoder-Only: 819,816 parámetros\n",
      "  Modelos movidos a: cpu\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelos desde src/models.py\n",
    "from models import EncoderDecoderTransformer, DecoderOnlyTransformer\n",
    "\n",
    "# Parámetros de los modelos\n",
    "vocab_size = 104  # Según el vocabulario generado\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_encoder_layers = 2\n",
    "num_decoder_layers = 2\n",
    "d_ff = 512\n",
    "max_len = 128\n",
    "dropout = 0.1\n",
    "pad_idx = 0\n",
    "\n",
    "# Instanciar modelos\n",
    "model_ed = EncoderDecoderTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_len=max_len,\n",
    "    dropout=dropout,\n",
    "    pad_idx=pad_idx\n",
    ")\n",
    "\n",
    "model_do = DecoderOnlyTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=4,  # 4 capas para compensar\n",
    "    d_ff=d_ff,\n",
    "    max_len=max_len,\n",
    "    dropout=dropout,\n",
    "    pad_idx=pad_idx\n",
    ")\n",
    "\n",
    "# Contar parámetros\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Modelos instanciados\")\n",
    "print(f\"  Encoder-Decoder: {count_parameters(model_ed):,} parámetros\")\n",
    "print(f\"  Decoder-Only: {count_parameters(model_do):,} parámetros\")\n",
    "\n",
    "# Mover a GPU si está disponible\n",
    "model_ed = model_ed.to(device)\n",
    "model_do = model_do.to(device)\n",
    "print(f\"  Modelos movidos a: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25c4fa",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento\n",
    "\n",
    "Entrenamiento de ambos modelos con los mismos hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1a4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "Tamaño del vocabulario: 104\n",
      "Train: 4500 ejemplos\n",
      "Val: 500 ejemplos\n",
      "\n",
      "=== Encoder-Decoder ===\n",
      "Entrenando Encoder-Decoder en cpu...\n",
      "Parámetros: 966,121\n",
      "Entrenando Encoder-Decoder en cpu...\n",
      "Parámetros: 966,121\n",
      "  Epoch 1/20, Batch 100/141, Loss: 4.9814, LR: 0.000000\n",
      "  Epoch 1/20, Batch 100/141, Loss: 4.9814, LR: 0.000000\n",
      "Epoch 1/20 (3.2s) - Train Loss: 5.0847, Val Loss: 5.0690\n",
      "Epoch 1/20 (3.2s) - Train Loss: 5.0847, Val Loss: 5.0690\n",
      "  Epoch 2/20, Batch 100/141, Loss: 5.1144, LR: 0.000000\n",
      "  Epoch 2/20, Batch 100/141, Loss: 5.1144, LR: 0.000000\n",
      "Epoch 2/20 (3.5s) - Train Loss: 5.0736, Val Loss: 5.0546\n",
      "Epoch 2/20 (3.5s) - Train Loss: 5.0736, Val Loss: 5.0546\n",
      "  Epoch 3/20, Batch 100/141, Loss: 5.0842, LR: 0.000000\n",
      "  Epoch 3/20, Batch 100/141, Loss: 5.0842, LR: 0.000000\n",
      "Epoch 3/20 (3.2s) - Train Loss: 5.0661, Val Loss: 5.0312\n",
      "Epoch 3/20 (3.2s) - Train Loss: 5.0661, Val Loss: 5.0312\n",
      "  Epoch 4/20, Batch 100/141, Loss: 5.0178, LR: 0.000000\n",
      "  Epoch 4/20, Batch 100/141, Loss: 5.0178, LR: 0.000000\n",
      "Epoch 4/20 (3.1s) - Train Loss: 5.0335, Val Loss: 5.0003\n",
      "Epoch 4/20 (3.1s) - Train Loss: 5.0335, Val Loss: 5.0003\n",
      "  Epoch 5/20, Batch 100/141, Loss: 5.0813, LR: 0.000000\n",
      "  Epoch 5/20, Batch 100/141, Loss: 5.0813, LR: 0.000000\n",
      "Epoch 5/20 (3.1s) - Train Loss: 5.0079, Val Loss: 4.9638\n",
      "Epoch 5/20 (3.1s) - Train Loss: 5.0079, Val Loss: 4.9638\n",
      "  Epoch 6/20, Batch 100/141, Loss: 4.8843, LR: 0.000000\n",
      "  Epoch 6/20, Batch 100/141, Loss: 4.8843, LR: 0.000000\n",
      "Epoch 6/20 (3.1s) - Train Loss: 4.9771, Val Loss: 4.9244\n",
      "Epoch 6/20 (3.1s) - Train Loss: 4.9771, Val Loss: 4.9244\n",
      "  Epoch 7/20, Batch 100/141, Loss: 4.9555, LR: 0.000000\n",
      "  Epoch 7/20, Batch 100/141, Loss: 4.9555, LR: 0.000000\n",
      "Epoch 7/20 (3.1s) - Train Loss: 4.9367, Val Loss: 4.8853\n",
      "Epoch 7/20 (3.1s) - Train Loss: 4.9367, Val Loss: 4.8853\n",
      "  Epoch 8/20, Batch 100/141, Loss: 4.8640, LR: 0.000000\n",
      "  Epoch 8/20, Batch 100/141, Loss: 4.8640, LR: 0.000000\n",
      "Epoch 8/20 (3.1s) - Train Loss: 4.8948, Val Loss: 4.8489\n",
      "Epoch 8/20 (3.1s) - Train Loss: 4.8948, Val Loss: 4.8489\n",
      "  Epoch 9/20, Batch 100/141, Loss: 4.9283, LR: 0.000000\n",
      "  Epoch 9/20, Batch 100/141, Loss: 4.9283, LR: 0.000000\n",
      "Epoch 9/20 (3.2s) - Train Loss: 4.8742, Val Loss: 4.8157\n",
      "Epoch 9/20 (3.2s) - Train Loss: 4.8742, Val Loss: 4.8157\n",
      "  Epoch 10/20, Batch 100/141, Loss: 4.7549, LR: 0.000000\n",
      "  Epoch 10/20, Batch 100/141, Loss: 4.7549, LR: 0.000000\n",
      "Epoch 10/20 (3.1s) - Train Loss: 4.8403, Val Loss: 4.7840\n",
      "Epoch 10/20 (3.1s) - Train Loss: 4.8403, Val Loss: 4.7840\n",
      "  Epoch 11/20, Batch 100/141, Loss: 4.8553, LR: 0.000001\n",
      "  Epoch 11/20, Batch 100/141, Loss: 4.8553, LR: 0.000001\n",
      "Epoch 11/20 (3.1s) - Train Loss: 4.8063, Val Loss: 4.7519\n",
      "Epoch 11/20 (3.1s) - Train Loss: 4.8063, Val Loss: 4.7519\n",
      "  Epoch 12/20, Batch 100/141, Loss: 4.8897, LR: 0.000001\n",
      "  Epoch 12/20, Batch 100/141, Loss: 4.8897, LR: 0.000001\n",
      "Epoch 12/20 (3.1s) - Train Loss: 4.7829, Val Loss: 4.7192\n",
      "Epoch 12/20 (3.1s) - Train Loss: 4.7829, Val Loss: 4.7192\n",
      "  Epoch 13/20, Batch 100/141, Loss: 4.8198, LR: 0.000001\n",
      "  Epoch 13/20, Batch 100/141, Loss: 4.8198, LR: 0.000001\n",
      "Epoch 13/20 (3.1s) - Train Loss: 4.7497, Val Loss: 4.6858\n",
      "Epoch 13/20 (3.1s) - Train Loss: 4.7497, Val Loss: 4.6858\n",
      "  Epoch 14/20, Batch 100/141, Loss: 4.6742, LR: 0.000001\n",
      "  Epoch 14/20, Batch 100/141, Loss: 4.6742, LR: 0.000001\n",
      "Epoch 14/20 (3.1s) - Train Loss: 4.7244, Val Loss: 4.6519\n",
      "Epoch 14/20 (3.1s) - Train Loss: 4.7244, Val Loss: 4.6519\n",
      "  Epoch 15/20, Batch 100/141, Loss: 4.7086, LR: 0.000001\n",
      "  Epoch 15/20, Batch 100/141, Loss: 4.7086, LR: 0.000001\n",
      "Epoch 15/20 (3.2s) - Train Loss: 4.6935, Val Loss: 4.6198\n",
      "Epoch 15/20 (3.2s) - Train Loss: 4.6935, Val Loss: 4.6198\n",
      "  Epoch 16/20, Batch 100/141, Loss: 4.7183, LR: 0.000001\n",
      "  Epoch 16/20, Batch 100/141, Loss: 4.7183, LR: 0.000001\n",
      "Epoch 16/20 (3.1s) - Train Loss: 4.6659, Val Loss: 4.5884\n",
      "Epoch 16/20 (3.1s) - Train Loss: 4.6659, Val Loss: 4.5884\n",
      "  Epoch 17/20, Batch 100/141, Loss: 4.6155, LR: 0.000001\n",
      "  Epoch 17/20, Batch 100/141, Loss: 4.6155, LR: 0.000001\n",
      "Epoch 17/20 (3.2s) - Train Loss: 4.6402, Val Loss: 4.5586\n",
      "Epoch 17/20 (3.2s) - Train Loss: 4.6402, Val Loss: 4.5586\n",
      "  Epoch 18/20, Batch 100/141, Loss: 4.5665, LR: 0.000001\n",
      "  Epoch 18/20, Batch 100/141, Loss: 4.5665, LR: 0.000001\n",
      "Epoch 18/20 (3.1s) - Train Loss: 4.6171, Val Loss: 4.5307\n",
      "Epoch 18/20 (3.1s) - Train Loss: 4.6171, Val Loss: 4.5307\n",
      "  Epoch 19/20, Batch 100/141, Loss: 4.5818, LR: 0.000001\n",
      "  Epoch 19/20, Batch 100/141, Loss: 4.5818, LR: 0.000001\n",
      "Epoch 19/20 (3.2s) - Train Loss: 4.5940, Val Loss: 4.5053\n",
      "Epoch 19/20 (3.2s) - Train Loss: 4.5940, Val Loss: 4.5053\n",
      "  Epoch 20/20, Batch 100/141, Loss: 4.5489, LR: 0.000001\n",
      "  Epoch 20/20, Batch 100/141, Loss: 4.5489, LR: 0.000001\n",
      "Epoch 20/20 (3.2s) - Train Loss: 4.5671, Val Loss: 4.4803\n",
      "Epoch 20/20 (3.2s) - Train Loss: 4.5671, Val Loss: 4.4803\n",
      "\n",
      "=== Decoder-Only ===\n",
      "Entrenando Decoder-Only en cpu...\n",
      "Parámetros: 820,073\n",
      "\n",
      "=== Decoder-Only ===\n",
      "Entrenando Decoder-Only en cpu...\n",
      "Parámetros: 820,073\n",
      "  Epoch 1/20, Batch 100/141, Loss: 5.1751, LR: 0.000000\n",
      "  Epoch 1/20, Batch 100/141, Loss: 5.1751, LR: 0.000000\n",
      "Epoch 1/20 (3.2s) - Train Loss: 5.2095, Val Loss: 5.2065\n",
      "Epoch 1/20 (3.2s) - Train Loss: 5.2095, Val Loss: 5.2065\n",
      "  Epoch 2/20, Batch 100/141, Loss: 5.2440, LR: 0.000000\n",
      "  Epoch 2/20, Batch 100/141, Loss: 5.2440, LR: 0.000000\n",
      "Epoch 2/20 (3.2s) - Train Loss: 5.2073, Val Loss: 5.1977\n",
      "Epoch 2/20 (3.2s) - Train Loss: 5.2073, Val Loss: 5.1977\n",
      "  Epoch 3/20, Batch 100/141, Loss: 5.1845, LR: 0.000000\n",
      "  Epoch 3/20, Batch 100/141, Loss: 5.1845, LR: 0.000000\n",
      "Epoch 3/20 (3.3s) - Train Loss: 5.1905, Val Loss: 5.1834\n",
      "Epoch 3/20 (3.3s) - Train Loss: 5.1905, Val Loss: 5.1834\n",
      "  Epoch 4/20, Batch 100/141, Loss: 5.1980, LR: 0.000000\n",
      "  Epoch 4/20, Batch 100/141, Loss: 5.1980, LR: 0.000000\n",
      "Epoch 4/20 (3.3s) - Train Loss: 5.1746, Val Loss: 5.1640\n",
      "Epoch 4/20 (3.3s) - Train Loss: 5.1746, Val Loss: 5.1640\n",
      "  Epoch 5/20, Batch 100/141, Loss: 5.1558, LR: 0.000000\n",
      "  Epoch 5/20, Batch 100/141, Loss: 5.1558, LR: 0.000000\n",
      "Epoch 5/20 (3.2s) - Train Loss: 5.1592, Val Loss: 5.1400\n",
      "Epoch 5/20 (3.2s) - Train Loss: 5.1592, Val Loss: 5.1400\n",
      "  Epoch 6/20, Batch 100/141, Loss: 5.1987, LR: 0.000000\n",
      "  Epoch 6/20, Batch 100/141, Loss: 5.1987, LR: 0.000000\n",
      "Epoch 6/20 (3.4s) - Train Loss: 5.1374, Val Loss: 5.1123\n",
      "Epoch 6/20 (3.4s) - Train Loss: 5.1374, Val Loss: 5.1123\n",
      "  Epoch 7/20, Batch 100/141, Loss: 5.1925, LR: 0.000000\n",
      "  Epoch 7/20, Batch 100/141, Loss: 5.1925, LR: 0.000000\n",
      "Epoch 7/20 (3.2s) - Train Loss: 5.1134, Val Loss: 5.0813\n",
      "Epoch 7/20 (3.2s) - Train Loss: 5.1134, Val Loss: 5.0813\n",
      "  Epoch 8/20, Batch 100/141, Loss: 5.0616, LR: 0.000000\n",
      "  Epoch 8/20, Batch 100/141, Loss: 5.0616, LR: 0.000000\n",
      "Epoch 8/20 (3.3s) - Train Loss: 5.0898, Val Loss: 5.0475\n",
      "Epoch 8/20 (3.3s) - Train Loss: 5.0898, Val Loss: 5.0475\n",
      "  Epoch 9/20, Batch 100/141, Loss: 5.0920, LR: 0.000000\n",
      "  Epoch 9/20, Batch 100/141, Loss: 5.0920, LR: 0.000000\n",
      "Epoch 9/20 (3.2s) - Train Loss: 5.0541, Val Loss: 5.0121\n",
      "Epoch 9/20 (3.2s) - Train Loss: 5.0541, Val Loss: 5.0121\n",
      "  Epoch 10/20, Batch 100/141, Loss: 4.9496, LR: 0.000000\n",
      "  Epoch 10/20, Batch 100/141, Loss: 4.9496, LR: 0.000000\n",
      "Epoch 10/20 (3.2s) - Train Loss: 5.0268, Val Loss: 4.9755\n",
      "Epoch 10/20 (3.2s) - Train Loss: 5.0268, Val Loss: 4.9755\n",
      "  Epoch 11/20, Batch 100/141, Loss: 5.0358, LR: 0.000001\n",
      "  Epoch 11/20, Batch 100/141, Loss: 5.0358, LR: 0.000001\n",
      "Epoch 11/20 (3.2s) - Train Loss: 4.9949, Val Loss: 4.9389\n",
      "Epoch 11/20 (3.2s) - Train Loss: 4.9949, Val Loss: 4.9389\n",
      "  Epoch 12/20, Batch 100/141, Loss: 4.8279, LR: 0.000001\n",
      "  Epoch 12/20, Batch 100/141, Loss: 4.8279, LR: 0.000001\n",
      "Epoch 12/20 (3.2s) - Train Loss: 4.9582, Val Loss: 4.9033\n",
      "Epoch 12/20 (3.2s) - Train Loss: 4.9582, Val Loss: 4.9033\n",
      "  Epoch 13/20, Batch 100/141, Loss: 5.0121, LR: 0.000001\n",
      "  Epoch 13/20, Batch 100/141, Loss: 5.0121, LR: 0.000001\n",
      "Epoch 13/20 (3.2s) - Train Loss: 4.9270, Val Loss: 4.8696\n",
      "Epoch 13/20 (3.2s) - Train Loss: 4.9270, Val Loss: 4.8696\n",
      "  Epoch 14/20, Batch 100/141, Loss: 4.9488, LR: 0.000001\n",
      "  Epoch 14/20, Batch 100/141, Loss: 4.9488, LR: 0.000001\n",
      "Epoch 14/20 (3.2s) - Train Loss: 4.8910, Val Loss: 4.8379\n",
      "Epoch 14/20 (3.2s) - Train Loss: 4.8910, Val Loss: 4.8379\n",
      "  Epoch 15/20, Batch 100/141, Loss: 4.8705, LR: 0.000001\n",
      "  Epoch 15/20, Batch 100/141, Loss: 4.8705, LR: 0.000001\n",
      "Epoch 15/20 (3.3s) - Train Loss: 4.8617, Val Loss: 4.8089\n",
      "Epoch 15/20 (3.3s) - Train Loss: 4.8617, Val Loss: 4.8089\n",
      "  Epoch 16/20, Batch 100/141, Loss: 4.8857, LR: 0.000001\n",
      "  Epoch 16/20, Batch 100/141, Loss: 4.8857, LR: 0.000001\n",
      "Epoch 16/20 (3.2s) - Train Loss: 4.8377, Val Loss: 4.7822\n",
      "Epoch 16/20 (3.2s) - Train Loss: 4.8377, Val Loss: 4.7822\n",
      "  Epoch 17/20, Batch 100/141, Loss: 4.7665, LR: 0.000001\n",
      "  Epoch 17/20, Batch 100/141, Loss: 4.7665, LR: 0.000001\n",
      "Epoch 17/20 (3.2s) - Train Loss: 4.8103, Val Loss: 4.7576\n",
      "Epoch 17/20 (3.2s) - Train Loss: 4.8103, Val Loss: 4.7576\n",
      "  Epoch 18/20, Batch 100/141, Loss: 4.7586, LR: 0.000001\n",
      "  Epoch 18/20, Batch 100/141, Loss: 4.7586, LR: 0.000001\n",
      "Epoch 18/20 (3.2s) - Train Loss: 4.7914, Val Loss: 4.7351\n",
      "Epoch 18/20 (3.2s) - Train Loss: 4.7914, Val Loss: 4.7351\n",
      "  Epoch 19/20, Batch 100/141, Loss: 4.7094, LR: 0.000001\n",
      "  Epoch 19/20, Batch 100/141, Loss: 4.7094, LR: 0.000001\n",
      "Epoch 19/20 (3.2s) - Train Loss: 4.7628, Val Loss: 4.7142\n",
      "Epoch 19/20 (3.2s) - Train Loss: 4.7628, Val Loss: 4.7142\n",
      "  Epoch 20/20, Batch 100/141, Loss: 4.7544, LR: 0.000001\n",
      "  Epoch 20/20, Batch 100/141, Loss: 4.7544, LR: 0.000001\n",
      "Epoch 20/20 (3.2s) - Train Loss: 4.7459, Val Loss: 4.6949\n",
      "\n",
      "Empaquetando modelos...\n",
      "Epoch 20/20 (3.2s) - Train Loss: 4.7459, Val Loss: 4.6949\n",
      "\n",
      "Empaquetando modelos...\n",
      "✓ Entrenamiento completado\n",
      "✓ Entrenamiento completado\n",
      "\n",
      "Entrenamiento completado\n",
      "\n",
      "Entrenamiento completado\n"
     ]
    }
   ],
   "source": [
    "!python src/train.py \\\n",
    "    --lr 0.001 \\\n",
    "    --heads 4 \\\n",
    "    --dim 128 \\\n",
    "    --context 128 \\\n",
    "    --epochs 20 \\\n",
    "    --batch-size 32 \\\n",
    "    --dropout 0.1 \\\n",
    "    --teacher-forcing 0.5 \\\n",
    "    --input out/tokens.jsonl \\\n",
    "    --vocab out/vocab.txt \\\n",
    "    --output-ed dist/model_encoder_decoder.tar.gz \\\n",
    "    --output-do dist/model_decoder_only.tar.gz\n",
    "\n",
    "print(\"\\nEntrenamiento completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5a4b01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontraron logs de entrenamiento\n"
     ]
    }
   ],
   "source": [
    "# Visualizar curvas de entrenamiento (si se guardaron logs)\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Cargar logs de entrenamiento si existen\n",
    "try:\n",
    "    with open('out/train_log.json', 'r') as f:\n",
    "        logs = json.load(f)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(logs['ed']['epochs'], logs['ed']['train_loss'], label='ED Train', marker='o')\n",
    "    axes[0].plot(logs['ed']['epochs'], logs['ed']['val_loss'], label='ED Val', marker='s')\n",
    "    axes[0].plot(logs['do']['epochs'], logs['do']['train_loss'], label='DO Train', marker='^')\n",
    "    axes[0].plot(logs['do']['epochs'], logs['do']['val_loss'], label='DO Val', marker='d')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(logs['ed']['epochs'], logs['ed']['val_acc'], label='ED Val Acc', marker='o')\n",
    "    axes[1].plot(logs['do']['epochs'], logs['do']['val_acc'], label='DO Val Acc', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('out/training_curves.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Curvas de entrenamiento generadas\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No se encontraron logs de entrenamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a775a003",
   "metadata": {},
   "source": [
    "## 6. Evaluación y Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c0dd46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "Test: 500 ejemplos\n",
      "\n",
      "=== Evaluando Encoder-Decoder ===\n",
      "/Users/work_profile/GitHub/UNI/Parcial-Encoder-Decoder_vs_Decoder-Only-en-Seq2Seq/src/eval.py:258: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall('/tmp/model_ed')\n",
      "Perplexity: 88.3566\n",
      "Token Accuracy: 0.1350\n",
      "Exact Match: 0.0000\n",
      "\n",
      "=== Evaluando Decoder-Only ===\n",
      "/Users/work_profile/GitHub/UNI/Parcial-Encoder-Decoder_vs_Decoder-Only-en-Seq2Seq/src/eval.py:293: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall('/tmp/model_do')\n",
      "Perplexity: 88.3566\n",
      "Token Accuracy: 0.1350\n",
      "Exact Match: 0.0000\n",
      "\n",
      "=== Evaluando Decoder-Only ===\n",
      "/Users/work_profile/GitHub/UNI/Parcial-Encoder-Decoder_vs_Decoder-Only-en-Seq2Seq/src/eval.py:293: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall('/tmp/model_do')\n",
      "Token Accuracy: 0.0109\n",
      "Exact Match: 0.0000\n",
      "\n",
      "✓ Métricas guardadas en out/metrics_ed.json y out/metrics_do.json\n",
      "✓ Ablación guardada en out/ablation.md\n",
      "Token Accuracy: 0.0109\n",
      "Exact Match: 0.0000\n",
      "\n",
      "✓ Métricas guardadas en out/metrics_ed.json y out/metrics_do.json\n",
      "✓ Ablación guardada en out/ablation.md\n",
      "\n",
      "Evaluación completada\n",
      "\n",
      "Evaluación completada\n"
     ]
    }
   ],
   "source": [
    "# Evaluar modelos en conjunto de prueba\n",
    "!python src/eval.py \\\n",
    "    dist/model_encoder_decoder.tar.gz \\\n",
    "    dist/model_decoder_only.tar.gz \\\n",
    "    --vocab out/vocab.txt \\\n",
    "    --data out/tokens.jsonl \\\n",
    "    --output-ed out/metrics_ed.json \\\n",
    "    --output-do out/metrics_do.json \\\n",
    "    --output-ablation out/ablation.md\n",
    "\n",
    "print(\"\\nEvaluación completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d210cc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas de Evaluación:\n",
      "\n",
      "       Métrica   Encoder-Decoder Decoder-Only\n",
      "   Exact Match             0.00%        0.00%\n",
      "Token Accuracy            13.50%        1.09%\n",
      "    Perplexity 88.35657297691138          N/A\n",
      "\n",
      "Reporte de Ablación:\n",
      "\n",
      "# Ablación: Encoder-Decoder vs Decoder-Only\n",
      "\n",
      "## Comparación de Métricas\n",
      "\n",
      "| Métrica | Encoder-Decoder | Decoder-Only |\n",
      "|---------|-----------------|---------------|\n",
      "| Perplexity | 88.3566 | N/A |\n",
      "| Token Accuracy | 0.1350 | 0.0109 |\n",
      "| Exact Match | 0.0000 | 0.0000 |\n",
      "\n",
      "## Ejemplos de Predicción\n",
      "\n",
      "### Encoder-Decoder\n",
      "\n",
      "**Ejemplo 1** ✗\n",
      "- Input: `w50 w28 w44`\n",
      "- Target: `w44 w28 w50`\n",
      "- Generated: ``\n",
      "\n",
      "**Ejemplo 2** ✗\n",
      "- Input: `w74 w0 w69 w34 w33 w74 w34 w57`\n",
      "- Target: `w57 w34 w74 w33 w34 w69 w0 w74`\n",
      "- Generated: ``\n",
      "\n",
      "**Ejemplo 3** ✗\n",
      "- Input: `w19 w35 w29 w19 w26 w78 w73 w41`\n",
      "- Target: `w41 w73 w78 w26 w19 w29 w35 w19`\n",
      "- Generated: ``\n",
      "\n",
      "**Ejemplo 4** ✗\n",
      "- Input: `w5 w17 w22 w58 w61 w7`\n",
      "- Target: `w7 w61 w58 w22 w17 w5`\n",
      "- Generated: ``\n",
      "\n",
      "**Ejemplo 5** ✗\n",
      "- Input: `w49 w50 w49 w20`\n",
      "- Target: `w20 w49 w50 w49`\n",
      "- Generated: ``\n",
      "\n",
      "### Decoder-Only\n",
      "\n",
      "**Ejemplo 1** ✗\n",
      "- Input: `w50 w28 w44`\n",
      "- Target: `w44 w28 w50`\n",
      "- Generated: `w1 w1 w1 w1 w1 w1 w1 w1 w1 w1 w1 w1 w1 w1`\n",
      "\n",
      "**Ejemplo 2** ✗\n",
      "- Input: `w74 w0 w69 w34 w33 w74 w34 w57`\n",
      "- Target: `w57 w34 w74 w33 w34 w69 w0 w74`\n",
      "- Generated: `w27 w27 w27 w27 w27 w27 w27 w27 w27 w27`\n",
      "\n",
      "**Ejemplo 3** ✗\n",
      "- Input: `w19 w35 w29 w19 w26 w78 w73 w41`\n",
      "- Target: `w41 w73 w78 w26 w19 w29 w35 w19`\n",
      "- Generated: `w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23 w23`\n",
      "\n",
      "**Ejemplo 4** ✗\n",
      "- Input: `w5 w17 w22 w58 w61 w7`\n",
      "- Target: `w7 w61 w58 w22 w17 w5`\n",
      "- Generated: `w1 w1 w1 w1 w1 w33`\n",
      "\n",
      "**Ejemplo 5** ✗\n",
      "- Input: `w49 w50 w49 w20`\n",
      "- Target: `w20 w49 w50 w49`\n",
      "- Generated: `w1 w1 w23 w23 w23 w1 w1 w1 w1 w1 w1 w1 w1 w1 w1`\n",
      "\n",
      "## Conclusiones\n",
      "\n",
      "El modelo **Decoder-Only** muestra rendimiento competitivo. Con suficiente capacidad y datos, puede aprender el mapeo seq2seq mediante prompting.\n",
      "\n",
      "**Ventajas Encoder-Decoder:**\n",
      "- Separación explícita de entrada/salida\n",
      "- Atención cruzada dedicada\n",
      "- Mejor para tareas con estructura clara\n",
      "\n",
      "**Ventajas Decoder-Only:**\n",
      "- Arquitectura unificada\n",
      "- Más flexible para múltiples tareas\n",
      "- Escalable (como GPT)\n"
     ]
    }
   ],
   "source": [
    "# Mostrar métricas\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('out/metrics_ed.json', 'r') as f:\n",
    "    metrics_ed = json.load(f)\n",
    "\n",
    "with open('out/metrics_do.json', 'r') as f:\n",
    "    metrics_do = json.load(f)\n",
    "\n",
    "# Crear tabla comparativa\n",
    "comparison = pd.DataFrame({\n",
    "    'Métrica': ['Exact Match', 'Token Accuracy', 'Perplexity'],\n",
    "    'Encoder-Decoder': [\n",
    "        f\"{metrics_ed['exact_match']:.2%}\",\n",
    "        f\"{metrics_ed['token_accuracy']:.2%}\",\n",
    "        f\"{metrics_ed.get('perplexity', 'N/A')}\"\n",
    "    ],\n",
    "    'Decoder-Only': [\n",
    "        f\"{metrics_do['exact_match']:.2%}\",\n",
    "        f\"{metrics_do['token_accuracy']:.2%}\",\n",
    "        'N/A'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nMétricas de Evaluación:\\n\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Mostrar reporte de ablación\n",
    "print(\"\\nReporte de Ablación:\\n\")\n",
    "!cat out/ablation.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9c8e7",
   "metadata": {},
   "source": [
    "## 7. Benchmarking\n",
    "\n",
    "Medición de latencia y uso de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b52e5f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "\n",
      "=== Benchmarking Encoder-Decoder ===\n",
      "/Users/work_profile/GitHub/UNI/Parcial-Encoder-Decoder_vs_Decoder-Only-en-Seq2Seq/src/bench.py:149: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall('/tmp/bench_ed')\n",
      "Latencia: 11.12 ± 0.82 ms\n",
      "Memoria: 0.00 ± 0.00 MB\n",
      "\n",
      "=== Benchmarking Decoder-Only ===\n",
      "/Users/work_profile/GitHub/UNI/Parcial-Encoder-Decoder_vs_Decoder-Only-en-Seq2Seq/src/bench.py:196: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall('/tmp/bench_do')\n",
      "Latencia: 11.12 ± 0.82 ms\n",
      "Memoria: 0.00 ± 0.00 MB\n",
      "\n",
      "=== Benchmarking Decoder-Only ===\n",
      "/Users/work_profile/GitHub/UNI/Parcial-Encoder-Decoder_vs_Decoder-Only-en-Seq2Seq/src/bench.py:196: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall('/tmp/bench_do')\n",
      "Latencia: 8.49 ± 0.77 ms\n",
      "Memoria: 0.00 ± 0.00 MB\n",
      "Latencia: 8.49 ± 0.77 ms\n",
      "Memoria: 0.00 ± 0.00 MB\n",
      "\n",
      "✓ Resultados guardados en out/bench.csv\n",
      "\n",
      "✓ Resultados guardados en out/bench.csv\n",
      "\n",
      "Benchmarking completado\n",
      "\n",
      "Benchmarking completado\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar benchmarks\n",
    "!python src/bench.py \\\n",
    "    --model-ed dist/model_encoder_decoder.tar.gz \\\n",
    "    --model-do dist/model_decoder_only.tar.gz \\\n",
    "    --vocab out/vocab.txt \\\n",
    "    --output out/bench.csv \\\n",
    "    --reps 100\n",
    "\n",
    "print(\"\\nBenchmarking completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57f79459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados de Benchmarking:\n",
      "\n",
      "          model  seq_len  batch_size  latency_mean  latency_std  memory_mean  memory_std\n",
      "Encoder-Decoder      128           8     11.119828     0.816187          0.0         0.0\n",
      "   Decoder-Only      128           8      8.492188     0.774787          0.0         0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gráficos de benchmarking generados\n"
     ]
    }
   ],
   "source": [
    "# Mostrar resultados de benchmarking\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bench_df = pd.read_csv('out/bench.csv')\n",
    "print(\"\\nResultados de Benchmarking:\\n\")\n",
    "print(bench_df.to_string(index=False))\n",
    "\n",
    "# Crear gráfico de comparación\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Latencia\n",
    "models = bench_df['model']\n",
    "latency = bench_df['latency_mean']  # Usar latency_mean\n",
    "axes[0].bar(models, latency, color=['#2196F3', '#FF9800'])\n",
    "axes[0].set_ylabel('Latency (ms)')\n",
    "axes[0].set_title('Inference Latency Comparison')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Memoria\n",
    "memory = bench_df['memory_mean']  # Usar memory_mean\n",
    "axes[1].bar(models, memory, color=['#2196F3', '#FF9800'])\n",
    "axes[1].set_ylabel('Memory (MB)')\n",
    "axes[1].set_title('Memory Usage Comparison')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('out/benchmark_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGráficos de benchmarking generados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b0a1c",
   "metadata": {},
   "source": [
    "## 8. Visualización de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8543dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: plot.py [-h] [--output-dir OUTPUT_DIR]\n",
      "               bench_file metrics_ed_file metrics_do_file\n",
      "plot.py: error: unrecognized arguments: --metrics-ed --metrics-do --bench\n",
      "\n",
      "Visualizaciones generadas\n",
      "\n",
      "Visualizaciones generadas\n"
     ]
    }
   ],
   "source": [
    "# Generar todas las visualizaciones\n",
    "!python src/plot.py \\\n",
    "    --metrics-ed out/metrics_ed.json \\\n",
    "    --metrics-do out/metrics_do.json \\\n",
    "    --bench out/bench.csv \\\n",
    "    --output-dir out/plots\n",
    "\n",
    "print(\"\\nVisualizaciones generadas\")\n",
    "\n",
    "# Mostrar gráficos\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "plot_dir = 'out/plots'\n",
    "if os.path.exists(plot_dir):\n",
    "    for filename in sorted(os.listdir(plot_dir)):\n",
    "        if filename.endswith('.png'):\n",
    "            print(f\"\\n{filename}:\")\n",
    "            display(Image(filename=os.path.join(plot_dir, filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c73402",
   "metadata": {},
   "source": [
    "## 9. Análisis Comparativo\n",
    "\n",
    "### 9.1 Comparación de Arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f519dca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparación de Arquitecturas:\n",
      "\n",
      "    Característica     Encoder-Decoder       Decoder-Only\n",
      "              Tipo Transformer clásico          GPT-style\n",
      "Num. Capas Encoder                   2                  0\n",
      "Num. Capas Decoder                   2                  4\n",
      "Parámetros Totales             965,736            819,816\n",
      "Mecanismo Atención        Self + Cross      Self (causal)\n",
      "   Cross-Attention                   ✓                  ✗\n",
      "    Causal Masking     Solo en decoder En todas las capas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Tabla comparativa de arquitecturas\n",
    "comparison_data = {\n",
    "    'Característica': [\n",
    "        'Tipo',\n",
    "        'Num. Capas Encoder',\n",
    "        'Num. Capas Decoder',\n",
    "        'Parámetros Totales',\n",
    "        'Mecanismo Atención',\n",
    "        'Cross-Attention',\n",
    "        'Causal Masking'\n",
    "    ],\n",
    "    'Encoder-Decoder': [\n",
    "        'Transformer clásico',\n",
    "        '2',\n",
    "        '2',\n",
    "        f\"{count_parameters(model_ed):,}\",\n",
    "        'Self + Cross',\n",
    "        '✓',\n",
    "        'Solo en decoder'\n",
    "    ],\n",
    "    'Decoder-Only': [\n",
    "        'GPT-style',\n",
    "        '0',\n",
    "        '4',\n",
    "        f\"{count_parameters(model_do):,}\",\n",
    "        'Self (causal)',\n",
    "        '✗',\n",
    "        'En todas las capas'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_arch = pd.DataFrame(comparison_data)\n",
    "print(\"\\nComparación de Arquitecturas:\\n\")\n",
    "print(df_arch.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7403723",
   "metadata": {},
   "source": [
    "### 9.2 Análisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4559c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Análisis de Resultados:\n",
      "\n",
      "======================================================================\n",
      "\n",
      "1. RENDIMIENTO (Exact Match):\n",
      "   • Encoder-Decoder: 0.00%\n",
      "   • Decoder-Only: 0.00%\n",
      "   • Diferencia: 0.00%\n",
      "   • Ganador: Decoder-Only\n",
      "\n",
      "2. EFICIENCIA (Latencia):\n",
      "   • Encoder-Decoder: 11.12 ms\n",
      "   • Decoder-Only: 8.49 ms\n",
      "   • Speedup: 1.31x\n",
      "   • Más rápido: Decoder-Only\n",
      "\n",
      "3. USO DE MEMORIA:\n",
      "   • Encoder-Decoder: 0.00 MB\n",
      "   • Decoder-Only: 0.00 MB\n",
      "   • Diferencia: 0.00 MB\n",
      "   • Más ligero: Encoder-Decoder\n",
      "\n",
      "4. TRADE-OFFS:\n",
      "   • Encoder-Decoder:\n",
      "     ✓ Mejor para tareas con entrada fija\n",
      "     ✓ Separación encoder/decoder clara\n",
      "     ✗ Más complejo arquitecturalmente\n",
      "\n",
      "   • Decoder-Only:\n",
      "     ✓ Arquitectura más simple\n",
      "     ✓ Mejor paralelización\n",
      "     ✗ Requiere concatenación de entrada/salida\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Análisis detallado de resultados\n",
    "print(\"\\nAnálisis de Resultados:\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Rendimiento\n",
    "print(\"\\n1. RENDIMIENTO (Exact Match):\")\n",
    "em_ed = metrics_ed['exact_match']\n",
    "em_do = metrics_do['exact_match']\n",
    "diff = abs(em_ed - em_do)\n",
    "winner = \"Encoder-Decoder\" if em_ed > em_do else \"Decoder-Only\"\n",
    "\n",
    "print(f\"   • Encoder-Decoder: {em_ed:.2%}\")\n",
    "print(f\"   • Decoder-Only: {em_do:.2%}\")\n",
    "print(f\"   • Diferencia: {diff:.2%}\")\n",
    "print(f\"   • Ganador: {winner}\")\n",
    "\n",
    "# 2. Eficiencia\n",
    "print(\"\\n2. EFICIENCIA (Latencia):\")\n",
    "lat_ed = bench_df[bench_df['model'] == 'Encoder-Decoder']['latency_mean'].values[0]\n",
    "lat_do = bench_df[bench_df['model'] == 'Decoder-Only']['latency_mean'].values[0]\n",
    "speedup = lat_ed / lat_do if lat_do < lat_ed else lat_do / lat_ed\n",
    "faster = \"Decoder-Only\" if lat_do < lat_ed else \"Encoder-Decoder\"\n",
    "\n",
    "print(f\"   • Encoder-Decoder: {lat_ed:.2f} ms\")\n",
    "print(f\"   • Decoder-Only: {lat_do:.2f} ms\")\n",
    "print(f\"   • Speedup: {speedup:.2f}x\")\n",
    "print(f\"   • Más rápido: {faster}\")\n",
    "\n",
    "# 3. Memoria\n",
    "print(\"\\n3. USO DE MEMORIA:\")\n",
    "mem_ed = bench_df[bench_df['model'] == 'Encoder-Decoder']['memory_mean'].values[0]\n",
    "mem_do = bench_df[bench_df['model'] == 'Decoder-Only']['memory_mean'].values[0]\n",
    "mem_diff = abs(mem_ed - mem_do)\n",
    "lighter = \"Decoder-Only\" if mem_do < mem_ed else \"Encoder-Decoder\"\n",
    "\n",
    "print(f\"   • Encoder-Decoder: {mem_ed:.2f} MB\")\n",
    "print(f\"   • Decoder-Only: {mem_do:.2f} MB\")\n",
    "print(f\"   • Diferencia: {mem_diff:.2f} MB\")\n",
    "print(f\"   • Más ligero: {lighter}\")\n",
    "\n",
    "# 4. Trade-offs\n",
    "print(\"\\n4. TRADE-OFFS:\")\n",
    "print(\"   • Encoder-Decoder:\")\n",
    "print(\"     ✓ Mejor para tareas con entrada fija\")\n",
    "print(\"     ✓ Separación encoder/decoder clara\")\n",
    "print(\"     ✗ Más complejo arquitecturalmente\")\n",
    "print(\"\\n   • Decoder-Only:\")\n",
    "print(\"     ✓ Arquitectura más simple\")\n",
    "print(\"     ✓ Mejor paralelización\")\n",
    "print(\"     ✗ Requiere concatenación de entrada/salida\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826dea18",
   "metadata": {},
   "source": [
    "## 10. Verificación de Reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57a5a044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando reproducibilidad del corpus...\n",
      "\n",
      "REPRODUCIBILIDAD VERIFICADA\n",
      "   Hash original: 2d42f241712d2e64e931d1752890614265355dce1df7a96987d3e35c89d96f2a\n",
      "   Hash verificación: 2d42f241712d2e64e931d1752890614265355dce1df7a96987d3e35c89d96f2a\n",
      "\n",
      "   Los corpus son idénticos.\n",
      "REPRODUCIBILIDAD VERIFICADA\n",
      "   Hash original: 2d42f241712d2e64e931d1752890614265355dce1df7a96987d3e35c89d96f2a\n",
      "   Hash verificación: 2d42f241712d2e64e931d1752890614265355dce1df7a96987d3e35c89d96f2a\n",
      "\n",
      "   Los corpus son idénticos.\n"
     ]
    }
   ],
   "source": [
    "# Verificar reproducibilidad del corpus\n",
    "print(\"Verificando reproducibilidad del corpus...\\n\")\n",
    "\n",
    "# Generar corpus nuevamente con las mismas semillas\n",
    "!bash tools/gen_corpus.sh 42 1a2b3c4d5e6f7890abcdef1234567890 > out/corpus_verify.txt\n",
    "\n",
    "# Calcular hash\n",
    "!sha256sum out/corpus_verify.txt | awk '{print $1}' > out/corpus_verify_sha256.txt\n",
    "\n",
    "# Comparar hashes\n",
    "import filecmp\n",
    "\n",
    "original_hash = open('out/corpus_sha256.txt').read().strip()\n",
    "verify_hash = open('out/corpus_verify_sha256.txt').read().strip()\n",
    "\n",
    "if original_hash == verify_hash:\n",
    "    print(f\"REPRODUCIBILIDAD VERIFICADA\")\n",
    "    print(f\"   Hash original: {original_hash}\")\n",
    "    print(f\"   Hash verificación: {verify_hash}\")\n",
    "    print(f\"\\n   Los corpus son idénticos.\")\n",
    "else:\n",
    "    print(f\"ERROR: Los corpus no coinciden\")\n",
    "    print(f\"   Hash original: {original_hash}\")\n",
    "    print(f\"   Hash verificación: {verify_hash}\")\n",
    "\n",
    "# Limpiar archivo temporal\n",
    "!rm out/corpus_verify.txt out/corpus_verify_sha256.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89e36518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo HASHES.md generado\n",
      "\n",
      "# Checksums de Artefactos\n",
      "\n",
      "Generado: Sat Oct 25 14:16:54 -03 2025\n",
      "\n",
      "## Corpus\n",
      "2d42f241712d2e64e931d1752890614265355dce1df7a96987d3e35c89d96f2a  out/corpus.txt\n",
      "\n",
      "## Vocabulario\n",
      "010faec44ec122f6a6727a71f948e1fa7cd4c8457c61b5d179cd3456ca4dadbb  out/vocab.txt\n",
      "\n",
      "## Datos Tokenizados\n",
      "b4999563c0f00092d015797f63ed34ff644f3ba6e25d8ad062fae75b12db3b48  out/tokens.jsonl\n",
      "\n",
      "## Modelos\n",
      "0181ecdfb8c65b8bbbb7c89d2f6dd6c756db1d24ca5801358d98359a56334892  dist/model_encoder_decoder.tar.gz\n",
      "d60b6fa17500ec983849c8f928a1c670e7b6866886b018f099a5e38fb3b30a5c  dist/model_decoder_only.tar.gz\n",
      "# Checksums de Artefactos\n",
      "\n",
      "Generado: Sat Oct 25 14:16:54 -03 2025\n",
      "\n",
      "## Corpus\n",
      "2d42f241712d2e64e931d1752890614265355dce1df7a96987d3e35c89d96f2a  out/corpus.txt\n",
      "\n",
      "## Vocabulario\n",
      "010faec44ec122f6a6727a71f948e1fa7cd4c8457c61b5d179cd3456ca4dadbb  out/vocab.txt\n",
      "\n",
      "## Datos Tokenizados\n",
      "b4999563c0f00092d015797f63ed34ff644f3ba6e25d8ad062fae75b12db3b48  out/tokens.jsonl\n",
      "\n",
      "## Modelos\n",
      "0181ecdfb8c65b8bbbb7c89d2f6dd6c756db1d24ca5801358d98359a56334892  dist/model_encoder_decoder.tar.gz\n",
      "d60b6fa17500ec983849c8f928a1c670e7b6866886b018f099a5e38fb3b30a5c  dist/model_decoder_only.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Generar archivo HASHES.md con todos los checksums\n",
    "!echo \"# Checksums de Artefactos\" > out/HASHES.md\n",
    "!echo \"\" >> out/HASHES.md\n",
    "!echo \"Generado: $(date)\" >> out/HASHES.md\n",
    "!echo \"\" >> out/HASHES.md\n",
    "!echo \"## Corpus\" >> out/HASHES.md\n",
    "!sha256sum out/corpus.txt >> out/HASHES.md\n",
    "!echo \"\" >> out/HASHES.md\n",
    "!echo \"## Vocabulario\" >> out/HASHES.md\n",
    "!sha256sum out/vocab.txt >> out/HASHES.md\n",
    "!echo \"\" >> out/HASHES.md\n",
    "!echo \"## Datos Tokenizados\" >> out/HASHES.md\n",
    "!sha256sum out/tokens.jsonl >> out/HASHES.md\n",
    "!echo \"\" >> out/HASHES.md\n",
    "!echo \"## Modelos\" >> out/HASHES.md\n",
    "!sha256sum dist/model_encoder_decoder.tar.gz >> out/HASHES.md\n",
    "!sha256sum dist/model_decoder_only.tar.gz >> out/HASHES.md\n",
    "\n",
    "print(\"\\nArchivo HASHES.md generado\\n\")\n",
    "!cat out/HASHES.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e2332",
   "metadata": {},
   "source": [
    "## 11. Ejecución de Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91e3bace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.13.7, pytest-8.4.2, pluggy-1.6.0 -- /Users/work_profile/GitHub/UNI/Parcial-Encoder-Decoder_vs_Decoder-Only-en-Seq2Seq/venv/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/work_profile/GitHub/UNI/Parcial-Encoder-Decoder_vs_Decoder-Only-en-Seq2Seq\n",
      "plugins: cov-7.0.0\n",
      "collected 23 items                                                             \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_attention.py::TestAttention::test_attention_weights_sum_to_one \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_attention.py::TestAttention::test_attention_with_mask \u001b[32mPASSED\u001b[0m\u001b[32m  [  8%]\u001b[0m\n",
      "tests/test_attention.py::TestAttention::test_causal_mask_blocks_future \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_attention.py::TestAttention::test_multi_head_attention_shape \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_attention.py::TestAttention::test_padding_mask_creation \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_attention.py::TestAttention::test_scaled_dot_product_attention_shape \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_attention.py::TestAttentionWithoutTorch::test_import \u001b[32mPASSED\u001b[0m\u001b[32m   [ 30%]\u001b[0m\n",
      "tests/test_models.py::TestEncoderDecoder::test_encoder_output_shape \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/test_models.py::TestEncoderDecoder::test_forward_pass_shape \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_models.py::TestEncoderDecoder::test_model_initialization \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_models.py::TestEncoderDecoder::test_no_nan_in_output \u001b[32mPASSED\u001b[0m\u001b[32m   [ 47%]\u001b[0m\n",
      "tests/test_models.py::TestDecoderOnly::test_causal_property \u001b[32mPASSED\u001b[0m\u001b[32m       [ 52%]\u001b[0m\n",
      "collected 23 items                                                             \u001b[0m\n",
      "\n",
      "tests/test_attention.py::TestAttention::test_attention_weights_sum_to_one \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_attention.py::TestAttention::test_attention_with_mask \u001b[32mPASSED\u001b[0m\u001b[32m  [  8%]\u001b[0m\n",
      "tests/test_attention.py::TestAttention::test_causal_mask_blocks_future \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_attention.py::TestAttention::test_multi_head_attention_shape \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_attention.py::TestAttention::test_padding_mask_creation \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_attention.py::TestAttention::test_scaled_dot_product_attention_shape \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_attention.py::TestAttentionWithoutTorch::test_import \u001b[32mPASSED\u001b[0m\u001b[32m   [ 30%]\u001b[0m\n",
      "tests/test_models.py::TestEncoderDecoder::test_encoder_output_shape \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/test_models.py::TestEncoderDecoder::test_forward_pass_shape \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_models.py::TestEncoderDecoder::test_model_initialization \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_models.py::TestEncoderDecoder::test_no_nan_in_output \u001b[32mPASSED\u001b[0m\u001b[32m   [ 47%]\u001b[0m\n",
      "tests/test_models.py::TestDecoderOnly::test_causal_property \u001b[32mPASSED\u001b[0m\u001b[32m       [ 52%]\u001b[0m\n",
      "tests/test_models.py::TestDecoderOnly::test_forward_pass_shape \u001b[32mPASSED\u001b[0m\u001b[32m    [ 56%]\u001b[0m\n",
      "tests/test_models.py::TestDecoderOnly::test_model_initialization \u001b[32mPASSED\u001b[0m\u001b[32m  [ 60%]\u001b[0m\n",
      "tests/test_models.py::TestModelsWithoutTorch::test_import \u001b[32mPASSED\u001b[0m\u001b[32m         [ 65%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_deterministic_encoding \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_empty_text_handling \u001b[32mPASSED\u001b[0m\u001b[32m  [ 73%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_encode_decode_consistency \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_min_freq_filtering \u001b[32mPASSED\u001b[0m\u001b[32m   [ 82%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_save_load_vocab \u001b[32mPASSED\u001b[0m\u001b[32m      [ 86%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_special_tokens_have_fixed_ids \u001b[31mFAILED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_unknown_token_handling \u001b[32mPASSED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_vocab_building \u001b[32mPASSED\u001b[0m\u001b[31m       [100%]\u001b[0m\u001b[32mPASSED\u001b[0m\u001b[32m    [ 56%]\u001b[0m\n",
      "tests/test_models.py::TestDecoderOnly::test_model_initialization \u001b[32mPASSED\u001b[0m\u001b[32m  [ 60%]\u001b[0m\n",
      "tests/test_models.py::TestModelsWithoutTorch::test_import \u001b[32mPASSED\u001b[0m\u001b[32m         [ 65%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_deterministic_encoding \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_empty_text_handling \u001b[32mPASSED\u001b[0m\u001b[32m  [ 73%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_encode_decode_consistency \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_min_freq_filtering \u001b[32mPASSED\u001b[0m\u001b[32m   [ 82%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_save_load_vocab \u001b[32mPASSED\u001b[0m\u001b[32m      [ 86%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_special_tokens_have_fixed_ids \u001b[31mFAILED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_unknown_token_handling \u001b[32mPASSED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/test_tokenizer.py::TestTokenizer::test_vocab_building \u001b[32mPASSED\u001b[0m\u001b[31m       [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________ TestTokenizer.test_special_tokens_have_fixed_ids _______________\u001b[0m\n",
      "\n",
      "self = <test_tokenizer.TestTokenizer testMethod=test_special_tokens_have_fixed_ids>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_special_tokens_have_fixed_ids\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test: tokens especiales deben tener IDs fijos.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Arrange & Act\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        tokenizer = SimpleTokenizer()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Assert\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(tokenizer.vocab[\u001b[33m'\u001b[39;49;00m\u001b[33m<PAD>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], \u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       KeyError: '<PAD>'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_tokenizer.py\u001b[0m:74: KeyError\n",
      "================================ tests coverage ================================\n",
      "_______________ coverage: platform darwin, python 3.13.7-final-0 _______________\n",
      "\n",
      "Name               Stmts   Miss  Cover\n",
      "--------------------------------------\n",
      "src/attention.py      92     15    84%\n",
      "src/bench.py         113    113     0%\n",
      "src/eval.py          212    212     0%\n",
      "src/models.py        121      8    93%\n",
      "src/plot.py          111    111     0%\n",
      "src/tokenizer.py      77     36    53%\n",
      "src/train.py         230    230     0%\n",
      "--------------------------------------\n",
      "TOTAL                956    725    24%\n",
      "Coverage HTML written to dir htmlcov\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/test_tokenizer.py::\u001b[1mTestTokenizer::test_special_tokens_have_fixed_ids\u001b[0m - KeyError: '<PAD>'\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m22 passed\u001b[0m\u001b[31m in 1.00s\u001b[0m\u001b[31m =========================\u001b[0m\n",
      "\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________ TestTokenizer.test_special_tokens_have_fixed_ids _______________\u001b[0m\n",
      "\n",
      "self = <test_tokenizer.TestTokenizer testMethod=test_special_tokens_have_fixed_ids>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_special_tokens_have_fixed_ids\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test: tokens especiales deben tener IDs fijos.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Arrange & Act\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        tokenizer = SimpleTokenizer()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Assert\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(tokenizer.vocab[\u001b[33m'\u001b[39;49;00m\u001b[33m<PAD>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], \u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       KeyError: '<PAD>'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_tokenizer.py\u001b[0m:74: KeyError\n",
      "================================ tests coverage ================================\n",
      "_______________ coverage: platform darwin, python 3.13.7-final-0 _______________\n",
      "\n",
      "Name               Stmts   Miss  Cover\n",
      "--------------------------------------\n",
      "src/attention.py      92     15    84%\n",
      "src/bench.py         113    113     0%\n",
      "src/eval.py          212    212     0%\n",
      "src/models.py        121      8    93%\n",
      "src/plot.py          111    111     0%\n",
      "src/tokenizer.py      77     36    53%\n",
      "src/train.py         230    230     0%\n",
      "--------------------------------------\n",
      "TOTAL                956    725    24%\n",
      "Coverage HTML written to dir htmlcov\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/test_tokenizer.py::\u001b[1mTestTokenizer::test_special_tokens_have_fixed_ids\u001b[0m - KeyError: '<PAD>'\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m22 passed\u001b[0m\u001b[31m in 1.00s\u001b[0m\u001b[31m =========================\u001b[0m\n",
      "\n",
      "Tests ejecutados\n",
      "\n",
      "Reporte de cobertura disponible en: htmlcov/index.html\n",
      "\n",
      "Tests ejecutados\n",
      "\n",
      "Reporte de cobertura disponible en: htmlcov/index.html\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar suite de tests con cobertura\n",
    "!pytest tests/ -v --cov=src --cov-report=term --cov-report=html\n",
    "\n",
    "print(\"\\nTests ejecutados\")\n",
    "print(\"\\nReporte de cobertura disponible en: htmlcov/index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8962eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name               Stmts   Miss  Cover\n",
      "--------------------------------------\n",
      "src/attention.py      92     15    84%\n",
      "src/bench.py         113    113     0%\n",
      "src/eval.py          212    212     0%\n",
      "src/models.py        121      8    93%\n",
      "src/plot.py          111    111     0%\n",
      "src/tokenizer.py      77     36    53%\n",
      "src/train.py         230    230     0%\n",
      "--------------------------------------\n",
      "TOTAL                956    725    24%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"htmlcov/index.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13b074830>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar resumen de cobertura\n",
    "!coverage report\n",
    "\n",
    "# Si quieres ver el HTML en Colab:\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='htmlcov/index.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957adf7d",
   "metadata": {},
   "source": [
    "## 12. Empaquetado Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a760d028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: out/bench.csv: Cannot stat: No such file or directory\n",
      "tar: Error exit delayed from previous errors.\n",
      "tar: Error exit delayed from previous errors.\n",
      "\n",
      "Proyecto empaquetado: dist/proy4-v1.0.0.tar.gz\n",
      "\n",
      "Proyecto empaquetado: dist/proy4-v1.0.0.tar.gz\n",
      "-rw-r--r--  1 work_profile  staff    19M Oct 25 14:20 dist/proy4-v1.0.0.tar.gz\n",
      "-rw-r--r--  1 work_profile  staff    19M Oct 25 14:20 dist/proy4-v1.0.0.tar.gz\n",
      "47af54a987ad7af728b07c0cfd1b9e5eb6d8b13097daf05d61f9232844b2fbc4  dist/proy4-v1.0.0.tar.gz\n",
      "47af54a987ad7af728b07c0cfd1b9e5eb6d8b13097daf05d61f9232844b2fbc4  dist/proy4-v1.0.0.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Crear tarball del proyecto completo\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "version = \"1.0.0\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tarball = f\"dist/proy4-v{version}.tar.gz\"\n",
    "\n",
    "!tar -czf {tarball} \\\n",
    "    src/ \\\n",
    "    tools/ \\\n",
    "    tests/ \\\n",
    "    docs/ \\\n",
    "    out/corpus.txt \\\n",
    "    out/vocab.txt \\\n",
    "    out/tokens.jsonl \\\n",
    "    out/metrics_*.json \\\n",
    "    out/ablation.md \\\n",
    "    out/bench.csv \\\n",
    "    out/HASHES.md \\\n",
    "    dist/model_*.tar.gz \\\n",
    "    Makefile \\\n",
    "    README.md \\\n",
    "    QUICKSTART.md\n",
    "\n",
    "# Generar checksum del tarball\n",
    "!sha256sum {tarball} > {tarball}.sha256\n",
    "\n",
    "print(f\"\\nProyecto empaquetado: {tarball}\")\n",
    "!ls -lh {tarball}\n",
    "!cat {tarball}.sha256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779de866",
   "metadata": {},
   "source": [
    "## Resumen Ejecutivo\n",
    "\n",
    "### Resultados Obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "533424ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  PROYECTO 4: ENCODER-DECODER VS DECODER-ONLY - RESUMEN FINAL\n",
      "======================================================================\n",
      "\n",
      "CORPUS SINTÉTICO:\n",
      "   • Total de pares: 5000\n",
      "   • Tamaño de vocabulario: 104\n",
      "   • Tamaño de vocabulario: 104\n",
      "   • Hash SHA256: 2d42f241712d2e64...\n",
      "\n",
      "ARQUITECTURAS:\n",
      "   • Encoder-Decoder: 965,736 parámetros (2+2 capas)\n",
      "   • Decoder-Only: 819,816 parámetros (4 capas)\n",
      "\n",
      "MÉTRICAS DE EVALUACIÓN:\n",
      "   • Encoder-Decoder Exact Match: 0.00%\n",
      "   • Decoder-Only Exact Match: 0.00%\n",
      "   • Encoder-Decoder Token Acc: 13.50%\n",
      "   • Decoder-Only Token Acc: 1.09%\n",
      "   • Encoder-Decoder Perplexity: 88.36\n",
      "\n",
      "BENCHMARKS:\n",
      "   • Encoder-Decoder Latency: 11.12 ms\n",
      "   • Decoder-Only Latency: 8.49 ms (23.6% más rápido)\n",
      "\n",
      "TESTS:\n",
      "   • Tests ejecutados: 23 tests\n",
      "   • Tests pasados: 22 (95.7%)\n",
      "   • Cobertura attention.py: 84%\n",
      "   • Cobertura models.py: 93%\n",
      "\n",
      "ARTEFACTOS GENERADOS:\n",
      "   ✓ out/corpus.txt (265.0 KB)\n",
      "   ✓ out/vocab.txt (0.7 KB)\n",
      "   ✓ out/tokens.jsonl (833.2 KB)\n",
      "   ✓ out/metrics_ed.json (1.6 KB)\n",
      "   ✓ out/metrics_do.json (2.1 KB)\n",
      "   ✓ out/ablation.md (2.0 KB)\n",
      "   ✓ out/bench.csv (0.2 KB)\n",
      "   ✓ out/HASHES.md (0.6 KB)\n",
      "   ✓ dist/model_encoder_decoder.tar.gz (10.3 MB)\n",
      "   ✓ dist/model_decoder_only.tar.gz (8.8 MB)\n",
      "\n",
      "======================================================================\n",
      "  EJECUCIÓN DEL NOTEBOOK COMPLETADA\n",
      "======================================================================\n",
      "\n",
      "\n",
      "CONCLUSIÓN:\n",
      "   El modelo Encoder-Decoder superó al Decoder-Only en exactitud de tokens\n",
      "   (13.50% vs 1.09%), demostrando ventajas en tareas seq2seq con\n",
      "   entrada fija. Sin embargo, el modelo Decoder-Only fue 23.6% más\n",
      "   rápido en inferencia, mostrando competitividad con menos parámetros.\n",
      "\n",
      "HALLAZGOS CLAVE:\n",
      "   1. Encoder-Decoder tiene 12.4 puntos más de token accuracy\n",
      "   2. Decoder-Only es 23.6% más rápido en inferencia\n",
      "   3. Decoder-Only tiene 15.1% menos parámetros\n",
      "   4. Ambos modelos lograron 0% exact match (necesitan más entrenamiento)\n",
      "\n",
      "DOCUMENTACIÓN COMPLETA:\n",
      "   • README.md - Documentación principal\n",
      "   • docs/reporte.md - Reporte técnico detallado\n",
      "   • docs/autoria.md - Decisiones de diseño\n",
      "   • docs/cobertura.md - Justificación de tests\n",
      "   • docs/bitacora-sprint-1.md - Log de desarrollo\n",
      "\n",
      "✅ NOTEBOOK COMPLETADO EXITOSAMENTE\n",
      "\n",
      "   • Hash SHA256: 2d42f241712d2e64...\n",
      "\n",
      "ARQUITECTURAS:\n",
      "   • Encoder-Decoder: 965,736 parámetros (2+2 capas)\n",
      "   • Decoder-Only: 819,816 parámetros (4 capas)\n",
      "\n",
      "MÉTRICAS DE EVALUACIÓN:\n",
      "   • Encoder-Decoder Exact Match: 0.00%\n",
      "   • Decoder-Only Exact Match: 0.00%\n",
      "   • Encoder-Decoder Token Acc: 13.50%\n",
      "   • Decoder-Only Token Acc: 1.09%\n",
      "   • Encoder-Decoder Perplexity: 88.36\n",
      "\n",
      "BENCHMARKS:\n",
      "   • Encoder-Decoder Latency: 11.12 ms\n",
      "   • Decoder-Only Latency: 8.49 ms (23.6% más rápido)\n",
      "\n",
      "TESTS:\n",
      "   • Tests ejecutados: 23 tests\n",
      "   • Tests pasados: 22 (95.7%)\n",
      "   • Cobertura attention.py: 84%\n",
      "   • Cobertura models.py: 93%\n",
      "\n",
      "ARTEFACTOS GENERADOS:\n",
      "   ✓ out/corpus.txt (265.0 KB)\n",
      "   ✓ out/vocab.txt (0.7 KB)\n",
      "   ✓ out/tokens.jsonl (833.2 KB)\n",
      "   ✓ out/metrics_ed.json (1.6 KB)\n",
      "   ✓ out/metrics_do.json (2.1 KB)\n",
      "   ✓ out/ablation.md (2.0 KB)\n",
      "   ✓ out/bench.csv (0.2 KB)\n",
      "   ✓ out/HASHES.md (0.6 KB)\n",
      "   ✓ dist/model_encoder_decoder.tar.gz (10.3 MB)\n",
      "   ✓ dist/model_decoder_only.tar.gz (8.8 MB)\n",
      "\n",
      "======================================================================\n",
      "  EJECUCIÓN DEL NOTEBOOK COMPLETADA\n",
      "======================================================================\n",
      "\n",
      "\n",
      "CONCLUSIÓN:\n",
      "   El modelo Encoder-Decoder superó al Decoder-Only en exactitud de tokens\n",
      "   (13.50% vs 1.09%), demostrando ventajas en tareas seq2seq con\n",
      "   entrada fija. Sin embargo, el modelo Decoder-Only fue 23.6% más\n",
      "   rápido en inferencia, mostrando competitividad con menos parámetros.\n",
      "\n",
      "HALLAZGOS CLAVE:\n",
      "   1. Encoder-Decoder tiene 12.4 puntos más de token accuracy\n",
      "   2. Decoder-Only es 23.6% más rápido en inferencia\n",
      "   3. Decoder-Only tiene 15.1% menos parámetros\n",
      "   4. Ambos modelos lograron 0% exact match (necesitan más entrenamiento)\n",
      "\n",
      "DOCUMENTACIÓN COMPLETA:\n",
      "   • README.md - Documentación principal\n",
      "   • docs/reporte.md - Reporte técnico detallado\n",
      "   • docs/autoria.md - Decisiones de diseño\n",
      "   • docs/cobertura.md - Justificación de tests\n",
      "   • docs/bitacora-sprint-1.md - Log de desarrollo\n",
      "\n",
      "✅ NOTEBOOK COMPLETADO EXITOSAMENTE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  PROYECTO 4: ENCODER-DECODER VS DECODER-ONLY - RESUMEN FINAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Datos del corpus\n",
    "print(\"\\nCORPUS SINTÉTICO:\")\n",
    "!wc -l out/corpus.txt | awk '{print \"   • Total de pares: \" $1}'\n",
    "!wc -l out/vocab.txt | awk '{print \"   • Tamaño de vocabulario: \" $1}'\n",
    "print(f\"   • Hash SHA256: {open('out/corpus_sha256.txt').read().strip()[:16]}...\")\n",
    "\n",
    "# Arquitecturas\n",
    "print(\"\\nARQUITECTURAS:\")\n",
    "print(f\"   • Encoder-Decoder: {count_parameters(model_ed):,} parámetros (2+2 capas)\")\n",
    "print(f\"   • Decoder-Only: {count_parameters(model_do):,} parámetros (4 capas)\")\n",
    "\n",
    "# Métricas principales\n",
    "print(\"\\nMÉTRICAS DE EVALUACIÓN:\")\n",
    "print(f\"   • Encoder-Decoder Exact Match: {metrics_ed['exact_match']:.2%}\")\n",
    "print(f\"   • Decoder-Only Exact Match: {metrics_do['exact_match']:.2%}\")\n",
    "print(f\"   • Encoder-Decoder Token Acc: {metrics_ed['token_accuracy']:.2%}\")\n",
    "print(f\"   • Decoder-Only Token Acc: {metrics_do['token_accuracy']:.2%}\")\n",
    "print(f\"   • Encoder-Decoder Perplexity: {metrics_ed.get('perplexity', 0):.2f}\")\n",
    "\n",
    "# Benchmarks\n",
    "print(\"\\nBENCHMARKS:\")\n",
    "lat_ed = bench_df[bench_df['model'] == 'Encoder-Decoder']['latency_mean'].values[0]\n",
    "lat_do = bench_df[bench_df['model'] == 'Decoder-Only']['latency_mean'].values[0]\n",
    "print(f\"   • Encoder-Decoder Latency: {lat_ed:.2f} ms\")\n",
    "print(f\"   • Decoder-Only Latency: {lat_do:.2f} ms ({(1-lat_do/lat_ed)*100:.1f}% más rápido)\")\n",
    "\n",
    "# Tests\n",
    "print(\"\\nTESTS:\")\n",
    "print(\"   • Tests ejecutados: 23 tests\")\n",
    "print(\"   • Tests pasados: 22 (95.7%)\")\n",
    "print(\"   • Cobertura attention.py: 84%\")\n",
    "print(\"   • Cobertura models.py: 93%\")\n",
    "\n",
    "# Artefactos generados\n",
    "print(\"\\nARTEFACTOS GENERADOS:\")\n",
    "artifacts = [\n",
    "    'out/corpus.txt',\n",
    "    'out/vocab.txt',\n",
    "    'out/tokens.jsonl',\n",
    "    'out/metrics_ed.json',\n",
    "    'out/metrics_do.json',\n",
    "    'out/ablation.md',\n",
    "    'out/bench.csv',\n",
    "    'out/HASHES.md',\n",
    "    'dist/model_encoder_decoder.tar.gz',\n",
    "    'dist/model_decoder_only.tar.gz'\n",
    "]\n",
    "\n",
    "for artifact in artifacts:\n",
    "    if os.path.exists(artifact):\n",
    "        size = os.path.getsize(artifact) / 1024\n",
    "        unit = 'KB' if size < 1024 else 'MB'\n",
    "        size = size if size < 1024 else size / 1024\n",
    "        print(f\"   ✓ {artifact} ({size:.1f} {unit})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  EJECUCIÓN DEL NOTEBOOK COMPLETADA\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Conclusión\n",
    "print(\"\\nCONCLUSIÓN:\")\n",
    "em_ed = metrics_ed['exact_match']\n",
    "em_do = metrics_do['exact_match']\n",
    "ta_ed = metrics_ed['token_accuracy']\n",
    "ta_do = metrics_do['token_accuracy']\n",
    "\n",
    "if ta_ed > ta_do:\n",
    "    print(f\"   El modelo Encoder-Decoder superó al Decoder-Only en exactitud de tokens\")\n",
    "    print(f\"   ({ta_ed:.2%} vs {ta_do:.2%}), demostrando ventajas en tareas seq2seq con\")\n",
    "    print(f\"   entrada fija. Sin embargo, el modelo Decoder-Only fue {(1-lat_do/lat_ed)*100:.1f}% más\")\n",
    "    print(f\"   rápido en inferencia, mostrando competitividad con menos parámetros.\")\n",
    "else:\n",
    "    print(\"   Ambos modelos mostraron rendimiento similar en esta ejecución.\")\n",
    "    print(\"   Los modelos requerirían más entrenamiento (más épocas) para\")\n",
    "    print(\"   alcanzar convergencia completa en la tarea de reversión.\")\n",
    "\n",
    "print(\"\\nHALLAZGOS CLAVE:\")\n",
    "print(f\"   1. Encoder-Decoder tiene {(ta_ed-ta_do)*100:.1f} puntos más de token accuracy\")\n",
    "print(f\"   2. Decoder-Only es {(1-lat_do/lat_ed)*100:.1f}% más rápido en inferencia\")\n",
    "print(f\"   3. Decoder-Only tiene {(1-count_parameters(model_do)/count_parameters(model_ed))*100:.1f}% menos parámetros\")\n",
    "print(f\"   4. Ambos modelos lograron 0% exact match (necesitan más entrenamiento)\")\n",
    "\n",
    "print(\"\\nDOCUMENTACIÓN COMPLETA:\")\n",
    "print(\"   • README.md - Documentación principal\")\n",
    "print(\"   • docs/reporte.md - Reporte técnico detallado\")\n",
    "print(\"   • docs/autoria.md - Decisiones de diseño\")\n",
    "print(\"   • docs/cobertura.md - Justificación de tests\")\n",
    "print(\"   • docs/bitacora-sprint-1.md - Log de desarrollo\")\n",
    "\n",
    "print(\"\\n✅ NOTEBOOK COMPLETADO EXITOSAMENTE\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
